{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"house-prices.csv\")\n",
    "df = pd.concat((df,pd.get_dummies(df[\"Brick\"]),pd.get_dummies(df[\"Neighborhood\"])),axis=1)\n",
    "del df[\"Brick\"]\n",
    "del df[\"Neighborhood\"]\n",
    "del df[\"No\"]#因为Yes = 1-No\n",
    "del df[\"North\"]\n",
    "del df[\"Home\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>               <td>OLS</td>         <td>Adj. R-squared:</td>      <td>0.861</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>         <td>y</td>               <td>AIC:</td>          <td>2729.3190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2017-11-10 16:04</td>        <td>BIC:</td>          <td>2752.1352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>128</td>         <td>Log-Likelihood:</td>     <td>-1356.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>7</td>           <td>F-statistic:</td>        <td>113.3</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>120</td>       <td>Prob (F-statistic):</td>  <td>8.25e-50</td> \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>R-squared:</td>            <td>0.869</td>            <td>Scale:</td>        <td>1.0038e+08</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>Coef.</th>   <th>Std.Err.</th>     <th>t</th>     <th>P>|t|</th>   <th>[0.025</th>      <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td>2159.4982</td> <td>8877.8097</td> <td>0.2432</td>  <td>0.8082</td> <td>-15417.9471</td> <td>19736.9435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>      <td>52.9937</td>   <td>5.7342</td>   <td>9.2416</td>  <td>0.0000</td>   <td>41.6403</td>     <td>64.3471</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>     <td>4246.7939</td> <td>1597.9108</td> <td>2.6577</td>  <td>0.0089</td>  <td>1083.0416</td>   <td>7410.5462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>     <td>7883.2785</td> <td>2117.0354</td> <td>3.7237</td>  <td>0.0003</td>  <td>3691.6957</td>  <td>12074.8613</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>-8267.4883</td> <td>1084.7768</td> <td>-7.6214</td> <td>0.0000</td> <td>-10415.2709</td> <td>-6119.7058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>17297.3495</td> <td>1981.6164</td> <td>8.7289</td>  <td>0.0000</td> <td>13373.8870</td>  <td>21220.8120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-1560.5791</td> <td>2396.7654</td> <td>-0.6511</td> <td>0.5162</td> <td>-6306.0079</td>   <td>3184.8496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>20681.0374</td> <td>3148.9538</td> <td>6.5676</td>  <td>0.0000</td> <td>14446.3280</td>  <td>26915.7467</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td>Omnibus:</td>    <td>3.026</td>  <td>Durbin-Watson:</td>   <td>1.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Prob(Omnibus):</td> <td>0.220</td> <td>Jarque-Bera (JB):</td> <td>2.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Skew:</td>     <td>0.268</td>     <td>Prob(JB):</td>     <td>0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Kurtosis:</td>   <td>3.421</td>  <td>Condition No.:</td>   <td>20328</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                  Results: Ordinary least squares\n",
       "===================================================================\n",
       "Model:              OLS              Adj. R-squared:     0.861     \n",
       "Dependent Variable: y                AIC:                2729.3190 \n",
       "Date:               2017-11-10 16:04 BIC:                2752.1352 \n",
       "No. Observations:   128              Log-Likelihood:     -1356.7   \n",
       "Df Model:           7                F-statistic:        113.3     \n",
       "Df Residuals:       120              Prob (F-statistic): 8.25e-50  \n",
       "R-squared:          0.869            Scale:              1.0038e+08\n",
       "-------------------------------------------------------------------\n",
       "           Coef.     Std.Err.    t    P>|t|     [0.025     0.975]  \n",
       "-------------------------------------------------------------------\n",
       "const     2159.4982 8877.8097  0.2432 0.8082 -15417.9471 19736.9435\n",
       "x1          52.9937    5.7342  9.2416 0.0000     41.6403    64.3471\n",
       "x2        4246.7939 1597.9108  2.6577 0.0089   1083.0416  7410.5462\n",
       "x3        7883.2785 2117.0354  3.7237 0.0003   3691.6957 12074.8613\n",
       "x4       -8267.4883 1084.7768 -7.6214 0.0000 -10415.2709 -6119.7058\n",
       "x5       17297.3495 1981.6164  8.7289 0.0000  13373.8870 21220.8120\n",
       "x6       -1560.5791 2396.7654 -0.6511 0.5162  -6306.0079  3184.8496\n",
       "x7       20681.0374 3148.9538  6.5676 0.0000  14446.3280 26915.7467\n",
       "-------------------------------------------------------------------\n",
       "Omnibus:                3.026        Durbin-Watson:           1.921\n",
       "Prob(Omnibus):          0.220        Jarque-Bera (JB):        2.483\n",
       "Skew:                   0.268        Prob(JB):                0.289\n",
       "Kurtosis:               3.421        Condition No.:           20328\n",
       "===================================================================\n",
       "* The condition number is large (2e+04). This might indicate\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用假设检验法\n",
    "import statsmodels.api as sm\n",
    "Y = df[\"Price\"].values\n",
    "X = df[[\"SqFt\",\"Bedrooms\",\"Bathrooms\",\"Offers\",\"Yes\",\"East\",\"West\"]].values\n",
    "X_ = sm.add_constant(X)\n",
    "#使用最小平方法\n",
    "result = sm.OLS(Y,X_)\n",
    "#fit方法运行计算\n",
    "summary = result.fit()\n",
    "#调用summary2方法，打印出假设检验的系列信息\n",
    "summary.summary2()\n",
    "#名词解释：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 名词解释\n",
    "###### Coef 回归系数\n",
    "###### Std.Err 标准差\n",
    "###### t 虚无假设成立时的t值\n",
    "###### P>|t| 虚无假设成立时的概率值\n",
    "###### [0.025 ,0.975] 97.5%置信估计\n",
    "###### 要做假设性检验，首先要设置显著性标准。a.假设显著性标准是0.01 b.推翻虚无假设的标准是 p < 0.01 c.上面的SqFt的t=9.2416,P（>t） = 0.0000 < 0.01,因此虚无假设被推翻（这里的虚无假设是SqFt对price的回归系数为0，即SqFt与price不相关）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F统计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 回归平方和 Regression Square Sum [RSS] :依变量的变化归咎于回归模型  A = sum((y-y*)^2)\n",
    "###### 误差平方和 Error Square Sum [ESS] : 依变量的变化归咎于线性模型  B = sum((y-y')^2)\n",
    "###### 总的平方和 Total Square Sum [TSS] : 依变量整体变化 C = A+B\n",
    "###### 回归平方平均  Model Mean Square: =RSS/Regression d.f(k) k=自变数的数量\n",
    "###### 误差平方平均 Error Mean Square:= ESS / Error d.f(n-k-1) n=观测值得数量\n",
    "###### F统计 F = Model Mean Square / Error Mean Square \n",
    "### F值越大越好，Prob(F-statistic)越小越好\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R Square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 回归可以解释的变异比例，可以作为自变量预测因变量准确度的指标\n",
    "###### SSE （残差平方和） = sum((y-y')^2)\n",
    "###### SST （整体平方和） = sum((yi-yavg)^2)\n",
    "###### R^2 = 1-SSE/SST 一般要大于0.6,0.7才算好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust R Square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### R^2 = 1-SSE/SST   SSE最小，推导出R^2不会递减 \n",
    "###### yi = b1x1 + b2x2 + .... bkxk + .... 增加任何一个变量还会增加R^2\n",
    "###### Adj R^2 = 1-(1-R^2)*((n-1)/(n-p-1))\n",
    "###### n为总体大小，p为回归因子个数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIC/BIC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### AIC （The Akaike Information  Criterion）= 2K + nln(SSE/n) k是参数数量，n是观察数，SSE是残差平方和。 AIC鼓励数据拟合的优良性，但是尽量避免出现过拟合，所以优先考虑的模型应该是AIC最小的那一个，赤池信息量的准则是寻找可以最好的解释数据但是包含最少自由参数的模型\n",
    "###### BIC (The Bayesain Information Criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择AIC最小的前10个数据组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SqFt', 'Bedrooms', 'Bathrooms', 'Offers', 'Yes', 'East', 'West']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = [\"SqFt\",\"Bedrooms\",\"Bathrooms\",\"Offers\",\"Yes\",\"East\",\"West\"]\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-875518b9e051>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mvaraibles\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpredictors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvaraibles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mpredictors2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictors2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "AICs = {}\n",
    "for k in range(1,len(fields)+1):\n",
    "    for varaibles in itertools.combinations(fields,k):\n",
    "        predictors = X[list(varaibles)]\n",
    "        predictors2 = sm.add_constant(predictors)\n",
    "        ols = sm.OLS(Y,predictors2)\n",
    "        res = ols.fit()\n",
    "        AICs[varaibles] = res.aic\n",
    "        \n",
    "from collections import Counter\n",
    "c = Counter(AICs)\n",
    "c.most_common()[::-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-cd6c0fd9cfaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlinear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SqFt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Bedrooms'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Bathrooms'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Offers'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Yes'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'West'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "#这里选用('SqFt', 'Bedrooms', 'Bathrooms', 'Offers', 'Yes', 'West')属性作为多元线性回归的特征属性\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear = LinearRegression()\n",
    "model = linear.fit(X[['SqFt', 'Bedrooms', 'Bathrooms', 'Offers', 'Yes', 'West']],Y)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-57c72e2fbc2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SqFt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Bedrooms'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Bathrooms'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Offers'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Yes'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'West'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "res = model.predict(X[['SqFt', 'Bedrooms', 'Bathrooms', 'Offers', 'Yes', 'West']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
