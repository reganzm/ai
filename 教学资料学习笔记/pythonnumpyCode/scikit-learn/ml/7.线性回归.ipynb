{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 前面介绍过用于分类的线性模型，其中为了将原来在实数域上的结果映射到（0，1）区间，引入了逻辑斯蒂函数。\n",
    "##### 而接下来的线性回归问题中，预测目标直接是实数域上面的数值，因此优化目标变得简单，即最小化预测结果和真实值之间的差异\n",
    "##### argminL(w,b) = argmin sum(f(w,x,b)-y^i)2\n",
    "##### 同样是需要计算w和b，有两种方法，一种是通过精确计算，另外一种是比较快速的随机梯度下降算法。Stochastic Gradient Descend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 使用波士顿房价数据来学习线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "df = load_boston()\n",
    "print(df.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.数据分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(df.data,df.target,test_size=0.25,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大值：50.0,最小值：5.0,离差：45.0,均值：22.5328063241\n"
     ]
    }
   ],
   "source": [
    "#对目标值进行分析\n",
    "print(\"最大值：%s,最小值：%s,离差：%s,均值：%s\"%(np.max(df.target),np.min(df.target),np.max(df.target)-np.min(df.target),np.mean(df.target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#从上面分析的结果来看，差异较大，为了避免个别较大的属性参数对整个线性回归模型产生的主导现象，这里需要对训练数据和目标数据都要标准化处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.测试数据与训练数据标准化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#特征标准化器\n",
    "ss_X = StandardScaler()\n",
    "#目标标准化器\n",
    "ss_Y = StandardScaler()\n",
    "\n",
    "#标准化\n",
    "x_train = ss_X.fit_transform(x_train)\n",
    "x_test = ss_X.transform(x_test)\n",
    "\n",
    "y_train = ss_Y.fit_transform(y_train.reshape(-1,1))\n",
    "y_test = ss_Y.transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.使用线性回归和SGDRegressor对波士顿房价做预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\softwares\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "lr_predict = lr.predict(x_test)\n",
    "\n",
    "sgdr = SGDRegressor()\n",
    "sgdr.fit(x_train,y_train.ravel())\n",
    "sgdr_predict = sgdr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.性能评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回归算法的性能评估和分类算法不一样，回归算法的预测值比一定精确到具体的目标值，但是我们可以通过计算预测值与目标值之间的距离来度量性能。\n",
    "#### 常用的度量指标是平均绝对误差Mean Absolute Error MAE和均方误差 Mean Squared Error MSE来度量，但是单单使用这两个指标还不够，\n",
    "#### 因为在不同的回归模型中，数据稍有变化MAE和MSE都会发生很大的变化，欠缺不同问题的可比性，因此我们要使用一个具有统计意义的指标，如同\n",
    "#### 分类任务中的精确率、准确率等。在回归中使用R-squared指标来衡量回归结果的波动可被真实值验证的百分比，他在一定程度上可以提现模型在数值\n",
    "#### 回归方面的能力\n",
    "#### R-squared计算方法\n",
    "#### R^2 = 1 - (SSres/SStot)\n",
    "#### SSres = sum((yi-f(xi))^2)\n",
    "#### SStot = sum((yi-ymean)^2)\n",
    "#### MSE = SStot / m\n",
    "#### MAE = SSabs/m\n",
    "#### SSabs = sum((abs(yi-ymean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearRegression R值： 0.686435486389\n",
      "sgdregressor R    值： 0.665446659784\n"
     ]
    }
   ],
   "source": [
    "print('linearRegression R值：',lr.score(x_test,y_test))\n",
    "print('sgdregressor R    值：',sgdr.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.使用scikit-learn内置的评价函数进行性能评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearRegression R-score: 0.686435486389 MAE: 0.370057351171 MSE: 0.28706703603\n",
      "sgdregressor R-score: 0.665446659784 MAE: 0.371131684462 MSE: 0.306282221363\n"
     ]
    }
   ],
   "source": [
    "print('linearRegression R-score: %s MAE: %s MSE: %s'%(r2_score(y_test,lr_predict),\n",
    "                                                  mean_absolute_error(y_test,lr_predict),mean_squared_error(y_test,lr_predict)))\n",
    "\n",
    "print('sgdregressor R-score: %s MAE: %s MSE: %s'%(r2_score(y_test,sgdr_predict),\n",
    "                                                  mean_absolute_error(y_test,sgdr_predict),mean_squared_error(y_test,sgdr_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearRegression MAE:3.43633538867,MSE:24.753484526\n",
      "sgdregressor MAE:3.46558777432,MSE:26.4424961259\n"
     ]
    }
   ],
   "source": [
    "#使用StandarScalar的inverse_transfor得到标准化值得原始值\n",
    "print('linearRegression MAE:%s,MSE:%s'%(mean_absolute_error(ss_Y.inverse_transform(lr_predict),ss_Y.inverse_transform(y_test)),\n",
    "                                       mean_squared_error(ss_Y.inverse_transform(lr_predict),ss_Y.inverse_transform(y_test))))\n",
    "\n",
    "print('sgdregressor MAE:%s,MSE:%s'%(mean_absolute_error(ss_Y.inverse_transform(sgdr_predict),ss_Y.inverse_transform(y_test)),\n",
    "                                       mean_squared_error(ss_Y.inverse_transform(sgdr_predict),ss_Y.inverse_transform(y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.特点分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 从结果可以看到线性回归的性能比随机梯度下降的性能要好，但是对于大数据集，随机梯度下降可以在不损失过多精度的情况下快速的完成预测。sklearn官网\n",
    "#### 推荐数据量大于10万的数据的回归操作，采用SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
